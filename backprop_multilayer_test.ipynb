{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "data   = np.asarray(digits.data, dtype='float32')\n",
    "target = np.asarray(digits.target, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.15, random_state=37)\n",
    "\n",
    "scaler  = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-------------------------------------------------------------\n",
    "def one_hot(n_classes: int, y: int):\n",
    "    # [y] - picks the row of the identity matrix, since thats\n",
    "    #       the row that contains the diagonal value (one-hot-encoding)\n",
    "    #       that we want.\n",
    "    return np.eye(n_classes)[y]\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# SOFTMAX__MANUAL\n",
    "def softmax(x):\n",
    "    assert isinstance(x, np.ndarray)\n",
    "    \n",
    "    exp = np.exp(x)\n",
    "    # print(np.sum(exp, axis=-1, keepdims=True))\n",
    "    return exp / np.sum(exp, axis=-1, keepdims=True)\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def get_activation_fn(p_activ_fn_str):\n",
    "    if p_activ_fn_str == \"sigmoid\":\n",
    "        return lambda p_z: sigmoid(p_z)\n",
    "\n",
    "    elif p_activ_fn_str == \"softmax\":\n",
    "        return lambda p_z: softmax(p_z)\n",
    "            \n",
    "#-------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n",
      "forward pass...\n",
      "shapes...\n",
      "W   shape - (1, 64)\n",
      "L-1 shape - (64, 1)\n",
      "b   shape - (64,)\n",
      "a   shape - (64, 64)\n",
      "L-1 shape - (64, 64)\n",
      "shapes...\n",
      "W   shape - (64, 10)\n",
      "L-1 shape - (64, 64)\n",
      "b   shape - (10,)\n",
      "a   shape - (64, 10)\n",
      "L-1 shape - (10, 64)\n",
      "shapes...\n",
      "W   shape - (10, 1)\n",
      "L-1 shape - (10, 64)\n",
      "b   shape - (1,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,64) and (10,1) not aligned: 64 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-3a304f0c2617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"forward pass...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel__forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-3a304f0c2617>\u001b[0m in \u001b[0;36mmodel__forward\u001b[0;34m(p_x, p_model)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# z = W * x + b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mZ\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0ma\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10,64) and (10,1) not aligned: 64 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "class Model:\n",
    "    def __init__(self, p_layers_lst):\n",
    "        self.layers_lst = p_layers_lst # :[:Layer]\n",
    "        \n",
    "class Layer:\n",
    "    def __init__(self, p_size_M, p_size_N, p_activ_fn_str):\n",
    "        self.W = np.random.uniform(size = (p_size_M, p_size_N), high=0.1, low=-0.1)\n",
    "        self.b = np.random.uniform(size = p_size_N,             high=0.1, low=-0.1)\n",
    "        \n",
    "        self.activation_fn = get_activation_fn(p_activ_fn_str)\n",
    "        \n",
    "#-------------------------------------------------------------\n",
    "def model__create():\n",
    "    layers_lst = []\n",
    "    for l in layers_specs_lst:\n",
    "        \n",
    "        size_M, size_N, activ_fn_str = l\n",
    "        \n",
    "        layer = Layer(size_M, size_N, activ_fn_str)\n",
    "        layers_lst.append(layer)\n",
    "    model = Model(layers_lst)\n",
    "    return model\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def model__forward(p_x, p_model):\n",
    "    \n",
    "    L_prev = p_x\n",
    "    for l in p_model.layers_lst:\n",
    "        \n",
    "        print(\"shapes...\")\n",
    "        print(\"W   shape - %s\"%(str(l.W.shape)))\n",
    "        print(\"L-1 shape - %s\"%(str(L_prev.shape)))\n",
    "        print(\"b   shape - %s\"%(str(l.b.shape)))\n",
    "        \n",
    "        # print(l.W)\n",
    "        # print(L_prev)\n",
    "        \n",
    "        # z = W * x + b\n",
    "        dot = np.dot(L_prev, l.W)\n",
    "        Z   = dot + l.b\n",
    "        a   = l.activation_fn(Z)\n",
    "        \n",
    "        print(\"a   shape - %s\"%(str(a.shape)))\n",
    "        \n",
    "        L_prev = np.transpose(a)\n",
    "        print(\"L-1 shape - %s\"%(str(L_prev.shape)))\n",
    "        \n",
    "    y = L_prev\n",
    "    return y\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "layers_specs_lst = [\n",
    "    (1, 64,  \"sigmoid\"),\n",
    "    (64, 10, \"sigmoid\"),\n",
    "    (10, 1,  \"softmax\")\n",
    "]\n",
    "model = model__create()\n",
    "\n",
    "\n",
    "x = X_test[0]\n",
    "\n",
    "# IMPORTANT!! - so that the image even though 1D array of 64pixels\n",
    "#               still comes in as a 2D numpy array 1x64. \n",
    "#               this is important to simplify code in forward pass\n",
    "#               (L_prev = np.transpose(a))\n",
    "x_input = x.reshape(x.shape[0], 1)\n",
    "\n",
    "print(x.reshape(1, x.shape[0]).shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\"forward pass...\")\n",
    "y = model__forward(x_input, model)\n",
    "\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
